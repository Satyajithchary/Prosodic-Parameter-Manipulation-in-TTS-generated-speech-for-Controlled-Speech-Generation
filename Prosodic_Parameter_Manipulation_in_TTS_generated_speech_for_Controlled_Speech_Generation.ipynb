{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyworld"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feCIe6GkEPp6",
        "outputId": "39f78ab1-992b-4403-eefd-f1db49e7829d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyworld\n",
            "  Downloading pyworld-0.3.4.tar.gz (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.0/252.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyworld) (1.25.2)\n",
            "Requirement already satisfied: cython>=0.24 in /usr/local/lib/python3.10/dist-packages (from pyworld) (3.0.10)\n",
            "Building wheels for collected packages: pyworld\n",
            "  Building wheel for pyworld (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.3.4-cp310-cp310-linux_x86_64.whl size=862465 sha256=542ecbc2decec59381dd3a31126424e5a38faad8a7a4c3f1a13c9b113a6cb6d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/09/8a/a1d79b73d59756f66e9bfe55a199840efc7473adb76ddacdfd\n",
            "Successfully built pyworld\n",
            "Installing collected packages: pyworld\n",
            "Successfully installed pyworld-0.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ziCXZIhTD0TI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pyworld as world\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def extract_features_for_comparison(audio_path):\n",
        "    y, sr = librosa.load(audio_path.numpy().decode('utf-8') if isinstance(audio_path, tf.Tensor) else audio_path, sr=None)\n",
        "    f0, _ = librosa.piptrack(y=y, sr=sr)\n",
        "    f0 = f0[f0 > 0]\n",
        "    energy = librosa.feature.rms(y=y)[0]\n",
        "    return y, sr, f0, energy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_features(human_features, tts_features):\n",
        "    human_y, human_sr, human_f0, human_energy = human_features\n",
        "    tts_y, tts_sr, tts_f0, tts_energy = tts_features\n",
        "\n",
        "    human_f0 = human_f0.numpy() if isinstance(human_f0, tf.Tensor) else human_f0\n",
        "    tts_f0 = tts_f0.numpy() if isinstance(tts_f0, tf.Tensor) else tts_f0\n",
        "    human_energy = human_energy.numpy() if isinstance(human_energy, tf.Tensor) else human_energy\n",
        "    tts_energy = tts_energy.numpy() if isinstance(tts_energy, tf.Tensor) else tts_energy\n",
        "\n",
        "    pitch_diff = np.mean(human_f0[human_f0 > 0]) - np.mean(tts_f0[tts_f0 > 0])\n",
        "\n",
        "    # Calculate duration ratio\n",
        "    duration_ratio = len(human_y) / len(tts_y)\n",
        "\n",
        "    # Calculate energy ratio\n",
        "    energy_ratio = np.mean(human_energy) / np.mean(tts_energy)\n",
        "\n",
        "    return np.float32(pitch_diff), np.float32(duration_ratio), np.float32(energy_ratio)\n"
      ],
      "metadata": {
        "id": "sTyHeDvAEOnf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_features(audio_path):\n",
        "    if isinstance(audio_path, tf.Tensor):\n",
        "        audio_path = audio_path.numpy().decode('utf-8')\n",
        "\n",
        "    # Load audio with dtype='float64' to match PyWorld's expectation\n",
        "    y, sr = librosa.load(audio_path, sr=None, dtype='float64')\n",
        "\n",
        "    if len(y) < sr * 0.1:\n",
        "        y = np.pad(y, (0, sr * 0.1 - len(y)), 'constant')\n",
        "\n",
        "    frame_period = min(5.0, 1000 * len(y) / sr / 100)\n",
        "    _f0, t = world.dio(y, sr, frame_period=frame_period)\n",
        "    f0 = world.stonemask(y, _f0, t, sr)\n",
        "    sp = world.cheaptrick(y, f0, t, sr)\n",
        "    ap = world.d4c(y, f0, t, sr)\n",
        "\n",
        "    return y, sr, f0.astype(np.float32), sp.astype(np.float32), ap.astype(np.float32)"
      ],
      "metadata": {
        "id": "tqMwpnGoEUG5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_comparison_features(human_audio, tts_audio):\n",
        "    def process_audio(audio):\n",
        "        y, sr, f0, energy = tf.py_function(extract_features_for_comparison, [audio], [tf.float32, tf.int32, tf.float32, tf.float32])\n",
        "        return y, sr, f0, energy\n",
        "\n",
        "    human_y, human_sr, human_f0, human_energy = process_audio(human_audio)\n",
        "    tts_y, tts_sr, tts_f0, tts_energy = process_audio(tts_audio)\n",
        "\n",
        "    def compare(human_features, tts_features):\n",
        "        pitch_diff, duration_ratio, energy_ratio = compare_features(human_features, tts_features)\n",
        "        return pitch_diff, duration_ratio, energy_ratio\n",
        "\n",
        "    pitch_diff, duration_ratio, energy_ratio = tf.py_function(\n",
        "        compare,\n",
        "        [human_y, human_sr, human_f0, human_energy, tts_y, tts_sr, tts_f0, tts_energy],  # Unpack tuples here\n",
        "        [tf.float32, tf.float32, tf.float32]\n",
        "    )\n",
        "\n",
        "    return tf.stack([pitch_diff, tf.math.log(duration_ratio), tf.math.log(energy_ratio)])"
      ],
      "metadata": {
        "id": "O3DIvNGyEej5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def apply_manipulations(tts_audio, parameters):\n",
        "    y, sr, f0, sp, ap = extract_features(tts_audio)\n",
        "    pitch_shift = parameters[0]\n",
        "    duration_factor = parameters[1]\n",
        "    energy_factor = parameters[2]\n",
        "\n",
        "    f0_modified, sp_modified, ap_modified = manipulate_features(\n",
        "        f0, sp, ap,\n",
        "        pitch_shift=pitch_shift,\n",
        "        duration_factor=tf.exp(duration_factor),\n",
        "        energy_factor=tf.exp(energy_factor)\n",
        "    )\n",
        "\n",
        "    y_synthesized = tf.py_function(synthesize_speech, [f0_modified, sp_modified, ap_modified, sr], tf.float32)\n",
        "    return y_synthesized, sr\n"
      ],
      "metadata": {
        "id": "lYW7QhcqEiUR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_similarity(human_audio, modified_tts_audio):\n",
        "    human_audio_path = human_audio.numpy().decode('utf-8') if isinstance(human_audio, tf.Tensor) else human_audio\n",
        "    human_y, human_sr = librosa.load(human_audio_path, sr=None)\n",
        "\n",
        "    def extract_data(tensor):\n",
        "        return tensor.numpy()\n",
        "\n",
        "    modified_tts_y, modified_tts_sr = tf.py_function(extract_data, [modified_tts_audio[0], modified_tts_audio[1]], [tf.float32, tf.int32])\n",
        "\n",
        "    human_y = tf.cond(\n",
        "        tf.equal(human_sr, modified_tts_sr),\n",
        "        lambda: human_y,\n",
        "        lambda: librosa.resample(y=human_y, orig_sr=human_sr, target_sr=modified_tts_sr.numpy())\n",
        "    )\n",
        "\n",
        "    min_len = min(len(human_y), len(modified_tts_y))\n",
        "    human_y = human_y[:min_len]\n",
        "    modified_tts_y = modified_tts_y[:min_len]\n",
        "\n",
        "\n",
        "    human_mfcc = tf.signal.mfccs_from_log_mel_spectrograms(\n",
        "        tf.signal.log_mel_spectrogram(\n",
        "            tf.cast(human_y, tf.float32),\n",
        "            sample_rate=modified_tts_sr,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    modified_tts_mfcc = tf.signal.mfccs_from_log_mel_spectrograms(\n",
        "        tf.signal.log_mel_spectrogram(\n",
        "            tf.cast(modified_tts_y, tf.float32),\n",
        "            sample_rate=modified_tts_sr,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    mfcc_similarity = tf.reduce_mean(tf.square(human_mfcc - modified_tts_mfcc))\n",
        "\n",
        "    return -mfcc_similarity # Negative for maximizing similarity during training"
      ],
      "metadata": {
        "id": "7M7CLgMXElRl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(3,)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(3)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "e5B7rtA7Ertm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_pitch_preserve_contour(f0, shift):\n",
        "    f0 = tf.cast(f0, dtype=tf.float32)\n",
        "    f0_log = tf.math.log(f0)\n",
        "    f0_mean = tf.reduce_mean(tf.boolean_mask(f0_log, f0 > 0))\n",
        "    f0_std = tf.math.reduce_std(tf.boolean_mask(f0_log, f0 > 0))\n",
        "    f0_normalized = (f0_log - f0_mean) / f0_std\n",
        "    shift = tf.cast(shift, dtype=tf.float32)\n",
        "    f0_shifted = tf.math.exp(f0_normalized * f0_std + f0_mean + shift)\n",
        "    return f0_shifted"
      ],
      "metadata": {
        "id": "zzw_WFmGEuRP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def modify_duration(feature, duration_factor):\n",
        "    feature = tf.convert_to_tensor(feature, dtype=tf.float32)\n",
        "    duration_factor = tf.cast(duration_factor, dtype=tf.float32)\n",
        "\n",
        "    feature = tf.reshape(feature, [-1])\n",
        "\n",
        "    original_length = tf.shape(feature)[0]\n",
        "    new_length = tf.cast(tf.cast(original_length, tf.float32) / duration_factor, tf.int32)\n",
        "\n",
        "    def numpy_interp(x, xp, fp):\n",
        "        return np.interp(x, xp, fp)\n",
        "\n",
        "    original_indices = tf.range(0, original_length, dtype=tf.float32)\n",
        "    new_indices = tf.range(0, new_length, dtype=tf.float32) * (tf.cast(original_length, tf.float32) - 1) / (tf.cast(new_length, tf.float32) - 1)\n",
        "\n",
        "    resized_feature = tf.numpy_function(numpy_interp, [new_indices, original_indices, feature], tf.float32)\n",
        "    resized_feature.set_shape([None])\n",
        "    return resized_feature\n"
      ],
      "metadata": {
        "id": "1pT19AkcFDIB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_energy(sp, energy_factor):\n",
        "    sp = tf.cast(sp, dtype=tf.float32)\n",
        "    energy_factor = tf.cast(energy_factor, dtype=tf.float32)\n",
        "    return sp * energy_factor"
      ],
      "metadata": {
        "id": "NnuYCMPAFE6e"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def manipulate_features(f0, sp, ap, pitch_shift=0.0, duration_factor=1.0, energy_factor=1.0):\n",
        "    f0 = tf.convert_to_tensor(f0, dtype=tf.float32)\n",
        "    sp = tf.convert_to_tensor(sp, dtype=tf.float32)\n",
        "    ap = tf.convert_to_tensor(ap, dtype=tf.float32)\n",
        "    pitch_shift = tf.cast(pitch_shift, dtype=tf.float32)\n",
        "    duration_factor = tf.cast(duration_factor, dtype=tf.float32)\n",
        "    energy_factor = tf.cast(energy_factor, dtype=tf.float32)\n",
        "\n",
        "    f0_modified = modify_pitch_preserve_contour(f0, pitch_shift)\n",
        "    f0_modified = modify_duration(f0_modified, duration_factor)\n",
        "    sp_modified = modify_energy(sp, energy_factor)\n",
        "    sp_modified = modify_duration(sp_modified, duration_factor)\n",
        "    ap_modified = modify_duration(ap, duration_factor)\n",
        "    return f0_modified, sp_modified, ap_modified"
      ],
      "metadata": {
        "id": "ULaNpve_FG2I"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(human_audio, tts_audio):\n",
        "    with tf.GradientTape() as tape:\n",
        "        features = extract_comparison_features(human_audio, tts_audio)\n",
        "        parameters = model(features[tf.newaxis, ...])\n",
        "        modified_tts = apply_manipulations(tts_audio, parameters[0])\n",
        "        loss = calculate_similarity(human_audio, modified_tts)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "def train_model(human_folder, tts_folder, num_epochs=10):\n",
        "    audio_pairs = []\n",
        "    for filename in os.listdir(human_folder):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            human_file = os.path.join(human_folder, filename)\n",
        "            tts_file = os.path.join(tts_folder, filename)\n",
        "            if os.path.exists(tts_file):\n",
        "                audio_pairs.append((human_file, tts_file))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for human_audio, tts_audio in audio_pairs:\n",
        "            loss = train_step(human_audio, tts_audio)\n",
        "            total_loss += loss\n",
        "        print(f\"Epoch {epoch + 1}, Average Loss: {total_loss / len(audio_pairs)}\")"
      ],
      "metadata": {
        "id": "Wu09P_q5FJ_l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_file_with_ml(human_input_file, tts_input_file, output_prefix):\n",
        "    features = extract_comparison_features(tf.constant(human_input_file), tf.constant(tts_input_file))\n",
        "    parameters = model(features[tf.newaxis, ...])\n",
        "\n",
        "    y, sr, f0, sp, ap = extract_features(tts_input_file)\n",
        "\n",
        "    f0_modified, sp_modified, ap_modified = manipulate_features(\n",
        "        f0, sp, ap,\n",
        "        pitch_shift=parameters[0, 0],\n",
        "        duration_factor=tf.exp(parameters[0, 1]),\n",
        "        energy_factor=tf.exp(parameters[0, 2])\n",
        "    )\n",
        "\n",
        "    y_synthesized = synthesize_speech(f0_modified.numpy(), sp_modified.numpy(), ap_modified.numpy(), sr)\n",
        "\n",
        "    sf.write(f'{output_prefix}_synthesized.wav', y_synthesized, sr)\n",
        "\n",
        "    plot_and_save_features(f0, f0_modified.numpy(), sp, sp_modified.numpy(), output_prefix)\n",
        "\n",
        "    print(f\"Processed file saved as {output_prefix}_synthesized.wav\")\n",
        "    print(f\"Feature comparisons saved as {output_prefix}_f0_comparison.png and {output_prefix}_spectral_envelope_comparison.png\")\n",
        "    print(f\"Original duration: {len(y)/sr:.2f}s, Modified duration: {len(y_synthesized)/sr:.2f}s\")"
      ],
      "metadata": {
        "id": "Q-gmMMNkFNLr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_files_with_ml(human_folder, tts_folder, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(human_folder):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            human_file = os.path.join(human_folder, filename)\n",
        "            tts_file = os.path.join(tts_folder, filename)\n",
        "\n",
        "            if os.path.exists(tts_file):\n",
        "                output_prefix = os.path.join(output_folder, os.path.splitext(filename)[0])\n",
        "                print(f\"Processing: {filename}\")\n",
        "                process_file_with_ml(human_file, tts_file, output_prefix)\n",
        "            else:\n",
        "                print(f\"TTS file not found for {filename}\")"
      ],
      "metadata": {
        "id": "ELRGhwl8FPNH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    ita_human_folder = '/content/drive/MyDrive/data (1)/data/wav/ITA/train'\n",
        "    ita_tts_folder = '/content/drive/MyDrive/Audio_Files/ITA_Train_TTS_Audios'\n",
        "    ita_output_folder = '/content/drive/MyDrive/Processed_Audios/ITA'\n",
        "\n",
        "    ger_human_folder = '/content/drive/MyDrive/data (1)/data/wav/GER/train'\n",
        "    ger_tts_folder = '/content/drive/MyDrive/Audio_Files/GER_Train_TTS_Audios'\n",
        "    ger_output_folder = '/content/drive/MyDrive/Processed_Audios/GER'\n",
        "\n",
        "    os.makedirs(ita_output_folder, exist_ok=True)\n",
        "    os.makedirs(ger_output_folder, exist_ok=True)\n",
        "\n",
        "    print(\"Training model on Italian files...\")\n",
        "    train_model(ita_human_folder, ita_tts_folder)\n",
        "\n",
        "    print(\"Processing Italian files...\")\n",
        "    process_all_files_with_ml(ita_human_folder, ita_tts_folder, ita_output_folder)\n",
        "\n",
        "    print(\"Training model on German files...\")\n",
        "    train_model(ger_human_folder, ger_tts_folder)\n",
        "\n",
        "    print(\"Processing German files...\")\n",
        "    process_all_files_with_ml(ger_human_folder, ger_tts_folder, ger_output_folder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "kd9Jxrp0EJLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Q0LGPrLFUcy"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}